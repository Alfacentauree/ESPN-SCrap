{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping in Python: Analyzing NBA Player Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erick Lu\n",
    "\n",
    "March 22, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be a tutorial on web scraping using Python’s urllib and regular expression (re) modules. I will be using these tools to write a python script that will “scrape” (obtain) data from the ESPN website and extract any relevant information (salaries, team names, etc.). Web scraping is a useful technique to learn that will allow you to extract data from websites that don’t offer formatted, raw data to the public. You can write scripts to automate the process of obtaining information from these websites, so that you don’t have to spend hours flipping through each page and copy-pasting.\n",
    "\n",
    "I will be collecting two statistics on the salaries of all the players in the NBA (As of currently, March 2020):\n",
    "1. the average salary paid to each individual team in the NBA.\n",
    "2.  the highest salary (and corresponding player) on each team in the NBA.\n",
    "\n",
    "Let’s first plan out how to do this in the easiest possible way, before diving into the code. The first we should do is take a look at the website to figure out which web pages we will be scraping information from.\n",
    "\n",
    "The teams page looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks very promising. All the team names are listed on this page, which means that they can easily be extracted from the page source. A good idea would be to have the python script obtain a list of all the teams from this specific URL, create the URLs for each team (format: http://espn.go.com/nba/team/roster/_/name/ + TEAM NAME) using that list, then systematically loop through all the team URLs and have the python script extract the player salaries from page sources of each of them.\n",
    "\n",
    "Let’s take a look at the page source to see if this is feasible:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, webpages that link to other webpages always have their links provided in some sort of pattern (look below the highlighted segment in the page source above). We’re going to take advantage of this.\n",
    "Let’s take a look at the Roster page within each team’s URL. Below is a screenshot (clickable) of the Boston Celtic’s roster page and page source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, looking at the page source reveals that each player’s name and information are all provided in a specific pattern, which we can take advantage of when using RegEx’s to extract snippets of data from each page source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the general structure of the website, we can begin to write the python script.\n",
    "Start by importing the “urllib” and “re” packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s create a function that will extract all the team names from the\n",
    "URL: http://espn.go.com/nba/teams, and return a list of each team’s roster URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atl': 'atlanta-hawks',\n",
       " 'bkn': 'brooklyn-nets',\n",
       " 'bos': 'boston-celtics',\n",
       " 'cha': 'charlotte-hornets',\n",
       " 'chi': 'chicago-bulls',\n",
       " 'cle': 'cleveland-cavaliers',\n",
       " 'dal': 'dallas-mavericks',\n",
       " 'den': 'denver-nuggets',\n",
       " 'det': 'detroit-pistons',\n",
       " 'gs': 'golden-state-warriors',\n",
       " 'hou': 'houston-rockets',\n",
       " 'ind': 'indiana-pacers',\n",
       " 'lac': 'la-clippers',\n",
       " 'lal': 'los-angeles-lakers',\n",
       " 'mem': 'memphis-grizzlies',\n",
       " 'mia': 'miami-heat',\n",
       " 'mil': 'milwaukee-bucks',\n",
       " 'min': 'minnesota-timberwolves',\n",
       " 'no': 'new-orleans-pelicans',\n",
       " 'ny': 'new-york-knicks',\n",
       " 'okc': 'oklahoma-city-thunder',\n",
       " 'orl': 'orlando-magic',\n",
       " 'phi': 'philadelphia-76ers',\n",
       " 'phx': 'phoenix-suns',\n",
       " 'por': 'portland-trail-blazers',\n",
       " 'sa': 'san-antonio-spurs',\n",
       " 'sac': 'sacramento-kings',\n",
       " 'tor': 'toronto-raptors',\n",
       " 'utah': 'utah-jazz',\n",
       " 'wsh': 'washington-wizards'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = urllib.request.urlopen('http://www.espn.com/nba/teams')\n",
    "words = f.read().decode('utf-8')\n",
    "\n",
    "re.findall\n",
    "\n",
    "teams = dict(re.findall(\"www\\.espn\\.com/nba/team/_/name/(\\w+)/(.+?)\\\",\", words))\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method finds the urls for each of the rosters in the NBA using regexes.\n",
    "def build_team_url():\n",
    "    # Open the espn teams webpage and extract the names of each roster available.\n",
    "    f = urllib.request.urlopen('http://www.espn.com/nba/teams')\n",
    "    words = f.read().decode('utf-8')\n",
    "    teams = dict(re.findall(\"www\\.espn\\.com/nba/team/_/name/(\\w+)/(.+?)\\\",\", words))\n",
    "    # Using the names of the rosters, this creates the urls of each roster in the NBA.\n",
    "    roster_urls = []\n",
    "    for key in teams.keys():\n",
    "        # each roster webpage follows this general pattern.\n",
    "        roster_urls.append('http://www.espn.com/nba/team/roster/_/name/' + key + '/' + teams[key])\n",
    "        teams[key] = str(teams[key])\n",
    "    return dict(zip(teams.values(), roster_urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosters = build_team_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atlanta-hawks': 'http://www.espn.com/nba/team/roster/_/name/atl/atlanta-hawks',\n",
       " 'boston-celtics': 'http://www.espn.com/nba/team/roster/_/name/bos/boston-celtics',\n",
       " 'brooklyn-nets': 'http://www.espn.com/nba/team/roster/_/name/bkn/brooklyn-nets',\n",
       " 'charlotte-hornets': 'http://www.espn.com/nba/team/roster/_/name/cha/charlotte-hornets',\n",
       " 'chicago-bulls': 'http://www.espn.com/nba/team/roster/_/name/chi/chicago-bulls',\n",
       " 'cleveland-cavaliers': 'http://www.espn.com/nba/team/roster/_/name/cle/cleveland-cavaliers',\n",
       " 'dallas-mavericks': 'http://www.espn.com/nba/team/roster/_/name/dal/dallas-mavericks',\n",
       " 'denver-nuggets': 'http://www.espn.com/nba/team/roster/_/name/den/denver-nuggets',\n",
       " 'detroit-pistons': 'http://www.espn.com/nba/team/roster/_/name/det/detroit-pistons',\n",
       " 'golden-state-warriors': 'http://www.espn.com/nba/team/roster/_/name/gs/golden-state-warriors',\n",
       " 'houston-rockets': 'http://www.espn.com/nba/team/roster/_/name/hou/houston-rockets',\n",
       " 'indiana-pacers': 'http://www.espn.com/nba/team/roster/_/name/ind/indiana-pacers',\n",
       " 'la-clippers': 'http://www.espn.com/nba/team/roster/_/name/lac/la-clippers',\n",
       " 'los-angeles-lakers': 'http://www.espn.com/nba/team/roster/_/name/lal/los-angeles-lakers',\n",
       " 'memphis-grizzlies': 'http://www.espn.com/nba/team/roster/_/name/mem/memphis-grizzlies',\n",
       " 'miami-heat': 'http://www.espn.com/nba/team/roster/_/name/mia/miami-heat',\n",
       " 'milwaukee-bucks': 'http://www.espn.com/nba/team/roster/_/name/mil/milwaukee-bucks',\n",
       " 'minnesota-timberwolves': 'http://www.espn.com/nba/team/roster/_/name/min/minnesota-timberwolves',\n",
       " 'new-orleans-pelicans': 'http://www.espn.com/nba/team/roster/_/name/no/new-orleans-pelicans',\n",
       " 'new-york-knicks': 'http://www.espn.com/nba/team/roster/_/name/ny/new-york-knicks',\n",
       " 'oklahoma-city-thunder': 'http://www.espn.com/nba/team/roster/_/name/okc/oklahoma-city-thunder',\n",
       " 'orlando-magic': 'http://www.espn.com/nba/team/roster/_/name/orl/orlando-magic',\n",
       " 'philadelphia-76ers': 'http://www.espn.com/nba/team/roster/_/name/phi/philadelphia-76ers',\n",
       " 'phoenix-suns': 'http://www.espn.com/nba/team/roster/_/name/phx/phoenix-suns',\n",
       " 'portland-trail-blazers': 'http://www.espn.com/nba/team/roster/_/name/por/portland-trail-blazers',\n",
       " 'sacramento-kings': 'http://www.espn.com/nba/team/roster/_/name/sac/sacramento-kings',\n",
       " 'san-antonio-spurs': 'http://www.espn.com/nba/team/roster/_/name/sa/san-antonio-spurs',\n",
       " 'toronto-raptors': 'http://www.espn.com/nba/team/roster/_/name/tor/toronto-raptors',\n",
       " 'utah-jazz': 'http://www.espn.com/nba/team/roster/_/name/utah/utah-jazz',\n",
       " 'washington-wizards': 'http://www.espn.com/nba/team/roster/_/name/wsh/washington-wizards'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets create a function that, for each team, will extract all the player names and salaries from the team’s ESPN roster URL, of the format http://espn.go.com/nba/team/roster/_/name/ + “TEAM NAME”,\n",
    "ie: http://espn.go.com/nba/team/roster/_/name/bos/boston-celtics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the url of each roster, extract the salary data using regexes and\n",
    "# perform calculations based on what we have extracted.\n",
    "def calculate_statistic(rosters):\n",
    "    # Create empty lists that will contain the statistics.\n",
    "    average_team_salaries = []\n",
    "    highest_salary_per_team = []\n",
    "    for url in rosters.values(): # Open website for each roster, one by one.\n",
    "        f = urllib.request.urlopen(url)\n",
    "        \n",
    "        stats = f.read().decode('utf-8')\n",
    "        '''\n",
    "        The salaries were embedded in the source code in this format:\n",
    "        <a href=\"http://www.espn.com/nba/player/_/id/3975/stephen-curry\">Stephen Curry</a>\n",
    "        </td><td>PG</td><td >29</td><td >6-3</td><td >190</td><td>Davidson</td><td>$34,382,550</td>\n",
    "        </tr><tr class=\"evenrow player-46-3202\"><td >35</td><td class=\"sortcell\">\n",
    "        '''\n",
    "        # This is the regex pattern to return players and their corresponding salary.\n",
    "        player_salaries = dict(re.findall('http\\://www\\.espn\\.com/nba/player/_/id/\\d*?/.*?\\\">(\\w+\\s\\w+)</a></td><td>\\w*?</td><td >\\d*?</td><td >.*?</td><td >\\d*?</td><td>.*?</td><td>(.*?)</td>', stats))\n",
    "        # in the dictionary, each player corresponds to a salary. change the salaries from strings to integers.\n",
    "        salaries = []\n",
    "        for key in player_salaries.keys():\n",
    "            if (str(player_salaries[key]) == '&nbsp;'):\n",
    "                player_salaries[key] = 'Not Reported'\n",
    "            else:\n",
    "                player_salaries[key] = int(re.sub(\"([,$])\",\"\", player_salaries[key]))\n",
    "                salaries.append (player_salaries[key])\n",
    "        # Sort the salaries and append them to the list,\n",
    "        # Also returns the person with the highest salary\n",
    "        highest_salary_per_team.append((str(find_key(player_salaries,sorted(salaries)[-1])),sorted(salaries)[-1]))\n",
    "        average_team_salaries.append(sum(salaries)/len(salaries))\n",
    "        sleep(1) # wait a second before opening next url so we don't get blocked\n",
    "        \n",
    "    # Prints the average salary out, with the team and salary side by side.\n",
    "    print (\"\\n\\nAverage Team Salaries in the NBA\\n(Average amount spent on each player)\\n\\n\")\n",
    "    team_with_salary = dict(zip(average_team_salaries, rosters.keys()))\n",
    "    average_team_salaries.sort()\n",
    "    for key in average_team_salaries:\n",
    "        print (team_with_salary[key], round(key,2))\n",
    "    # Prints the highest salaries out, with the team and salary side by side.\n",
    "    team_with_highest = dict(zip(highest_salary_per_team, rosters.keys() ))\n",
    "    highest_salary_per_team.sort(key=lambda highest_salary_per_team: highest_salary_per_team[1])\n",
    "    print (\"\\n\\nPlayer with the highest salary per team in the NBA\\n\\n\")\n",
    "    for key in highest_salary_per_team:\n",
    "        print (team_with_highest[key], key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function’s defined, we can write a few lines of code to execute each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'urllib' has no attribute 'urlopen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c5db3e825fec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrosters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_team_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcalculate_statistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrosters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8ac3a56617ad>\u001b[0m in \u001b[0;36mbuild_team_url\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Open the webpage containing links to each roster,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# and extract the names of each roster available.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://www.espn.com/nba/teams'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mteams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"www\\.espn\\.com/nba/team/_/name/(\\w+)/(.+?)\\\"\\sclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'urllib' has no attribute 'urlopen'"
     ]
    }
   ],
   "source": [
    "rosters = build_team_url()\n",
    "calculate_statistic(rosters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is achieved by looping through all the team rosters on the ESPN website, then looping through all the players and extracting their salaries. The average salary per team is obtained by simply adding together the salaries and dividing by the number of people per team. I also use a simple sort function in Python to be able to see which player on each team is the highest paid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data, we can see who is paid the most.\n",
    "\n",
    "Thanks for reading! I hope my code helped you understand how to perform basic web scraping using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
